{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Law of Large Numbers and Central Limit Theorem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will experimentally motivate two of the most important theorems in probability theory, which we will prove later in class: the Law of Large Numbers and the Central Limit Theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coin Toss Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with our most basic experiment in probability theory: flipping a fair coin. In this notebook, we'll denote a 'heads' outcome as `0` and a 'tails' outcome as `1`, since this will be simpler to represent in our code.\n",
    "\n",
    "Then the space of outcomes is\n",
    "$$\n",
    "\\Omega = \\{0,1\\}\n",
    "$$\n",
    "and the probability function $P: \\mathcal{P}(\\Omega) \\to \\mathbb{R}$ satisfies\n",
    "$$\n",
    "P(\\{0\\}) = P(\\{1\\}) = \\frac{1}{2}.\n",
    "$$\n",
    "\n",
    "Consider the random variable $X:\\Omega \\to \\mathbb{R}$ given by 'number of tails flipped'. That is,\n",
    "$$\n",
    "X(0) = 0 \\quad \\mbox{and} \\quad X(1) = 1.\n",
    "$$\n",
    "The probability mass function (pmf) for $X$ is defined by \n",
    "$$\n",
    "p_X(t) = \\left\\{\\begin{array}{lr}\n",
    "\\frac{1}{2} & t = 0 \\mbox{ or } 1 \\\\\n",
    "0 & \\mbox{otherwise.} \\end{array}\\right.\n",
    "$$\n",
    "\n",
    "As we have calculated before, the expected value of $X$ is given by \n",
    "$$\n",
    "\\mathbb{E}[X] = 0 \\cdot p_X(0) + 1 \\cdot p_X(1) = 0 \\cdot \\frac{1}{2} + 1 \\cdot \\frac{1}{2} = \\frac{1}{2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Law of Large Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Empirical Mean\n",
    "\n",
    "Now suppose you run the experiment $n$ times---i.e., flip the coin $n$ times. Each time you run the experiment, you record the value of $X$ for that iteration, and you take the average after $n$ flips. That is, you record whether the coin landed heads (value of `0`) or tails (value of `1`) in each experiment, and take the mean of all the values you get. \n",
    "\n",
    "**Question:** What do you expect this running average to be as $n$ gets large?\n",
    "\n",
    "Let's test your intuition by running a simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulating a Coin Toss\n",
    "\n",
    "The following function simulates a coin toss. It works by:\n",
    "- generating a random real between 0 and 1\n",
    "- rounding the result\n",
    "- turning the resulting 0.0 or 1.0 into an integer 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toss_coin():\n",
    "    \n",
    "    return int(np.round(np.random.rand()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test\n",
    "\n",
    "result = toss_coin()\n",
    "if result == 0:\n",
    "    result_string = '(heads)'\n",
    "else:\n",
    "    result_string = '(tails)'\n",
    "    \n",
    "print(result, result_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running a Small Simulation\n",
    "\n",
    "Let's run a simulation where we toss the coin multiple times and keep a running average. We'll start with a small simulation, so that we can eyeball the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_n = 10\n",
    "\n",
    "outcomes = []\n",
    "\n",
    "# Print table headers with alignment\n",
    "print(f\"{'n':^3} {'outcomes':^40} {'running average':^17}\")\n",
    "print(f\"{'-'*3} {'-'*40} {'-'*17}\")\n",
    "\n",
    "# Simulate and print outcomes with formatting\n",
    "for n in range(total_n):\n",
    "    outcome = toss_coin()\n",
    "    outcomes.append(outcome)\n",
    "    print(f\"{n:^3} {str(outcomes):^40} {np.mean(outcomes):^17.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Longer Simulation\n",
    "\n",
    "The above illustrates the setup, but it's hard to see a trend in the running average. Let's run the simulation for more iterations and plot the resulting running average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_n = 100\n",
    "\n",
    "outcomes = []\n",
    "running_averages = []\n",
    "\n",
    "for n in range(total_n):\n",
    "    outcome = toss_coin()\n",
    "    outcomes.append(outcome)\n",
    "    running_averages.append(np.mean(outcomes))\n",
    "    \n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot([0.5]*total_n,'--')\n",
    "plt.plot(running_averages)\n",
    "ax = plt.gca()\n",
    "ax.set_ylim([-0.1, 1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try running this simulation a few times and plot the results on the same axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 5\n",
    "total_n = 100\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot([0.5]*total_n,'--')\n",
    "\n",
    "for experiment in range(num_runs):\n",
    "    outcomes = []\n",
    "    running_averages = []\n",
    "\n",
    "    for n in range(total_n):\n",
    "        outcome = toss_coin()\n",
    "        outcomes.append(outcome)\n",
    "        running_averages.append(np.mean(outcomes))\n",
    "\n",
    "    plt.plot(running_averages)\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.set_ylim([-0.1, 1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's try it with a larger number of tosses in each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "total_n = 1000\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot([0.5]*total_n,'--')\n",
    "\n",
    "for experiment in range(num_runs):\n",
    "    outcomes = []\n",
    "    running_averages = []\n",
    "\n",
    "    for n in range(total_n):\n",
    "        outcome = toss_coin()\n",
    "        outcomes.append(outcome)\n",
    "        running_averages.append(np.mean(outcomes))\n",
    "\n",
    "    plt.plot(running_averages)\n",
    "    \n",
    "ax = plt.gca()\n",
    "ax.set_ylim([-0.1, 1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Apparently, the running average converges to the expected value each time. Hopefully, this agrees with your intuition!\n",
    "\n",
    "This illustrates the **Law of Large Numbers**, which *roughly* says: The running average of the random variable $X$ after $n$ trials limits to $\\mathbb{E}[X]$ as $n \\to \\infty$.  \n",
    "\n",
    "We will give a precise statement of this theorem in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem\n",
    "\n",
    "We can refine the above experimental results. Our simulations indicate that the running average tends to the expected value. We can also say something about the 'shape' of the deviation of the running average from the expected value.\n",
    "\n",
    "Let's try to get a feel for the meaning of this statement through the same 'coin flip' experiment above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix a number of times `n` to flip the coin in a single 'run', and consider the average value of $X$ over these $n$ coin flips (i.e., average number of 'tails' that were flipped). \n",
    "\n",
    "Now, as above, consider doing multiple 'runs' of this multiple coin flip experiment, and keep track of all averages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small Simulation\n",
    "\n",
    "The following will run the above on a small example to illustrate the idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10\n",
    "total_n = 10\n",
    "\n",
    "\n",
    "# Print table headers with alignment\n",
    "print(f\"{'run':^3} {'outcomes':^40} {'average num tails':^17}\")\n",
    "print(f\"{'-'*3} {'-'*40} {'-'*17}\")\n",
    "\n",
    "means = []\n",
    "      \n",
    "for run in range(num_runs):\n",
    "    outcomes = []\n",
    "    # Simulate and print outcomes with formatting\n",
    "    for n in range(total_n):\n",
    "        outcome = toss_coin()\n",
    "        outcomes.append(outcome)\n",
    "    print(f\"{run:^3} {str(outcomes):^40} {np.mean(outcomes):^17.2f}\")\n",
    "    means.append(np.mean(outcomes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not so easy to interpret. Observe that we saved the means in a list. The interpretation we are after is checking the shape of the 'distribution of means'. To do this, let's look at a histogram of the means list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "plt.hist(means)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we did so few runs, this doesn't have any obviously interesting shape, although it seems to have a max around 0.5. Let's run larger simulations to get a better idea of what's going on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Large Simulation and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 100\n",
    "total_n = 100\n",
    "\n",
    "\n",
    "means = []\n",
    "      \n",
    "for run in range(num_runs):\n",
    "    outcomes = []\n",
    "    for n in range(total_n):\n",
    "        outcome = toss_coin()\n",
    "        outcomes.append(outcome)\n",
    "    means.append(np.mean(outcomes))\n",
    "    \n",
    "plt.figure(figsize = (10,7))\n",
    "plt.hist(means,bins = int(np.ceil(num_runs/20)))\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...This looks a little more interesting. Let's continue expanding the size of the simulation..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 1000\n",
    "total_n = 1000\n",
    "\n",
    "\n",
    "means = []\n",
    "      \n",
    "for run in range(num_runs):\n",
    "    outcomes = []\n",
    "    for n in range(total_n):\n",
    "        outcome = toss_coin()\n",
    "        outcomes.append(outcome)\n",
    "    means.append(np.mean(outcomes))\n",
    "    \n",
    "plt.figure(figsize = (10,7))\n",
    "plt.hist(means,bins = int(np.ceil(num_runs/50)))\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This appears to have some structure. Once again, we see that it appears to have a max around 0.5---i.e., the expected value of the experiment. The next block of code pins down exactly what that structure is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing to a Gaussian Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's randomly sample `num_runs` points from a Gaussian distribution. Specifically, we'll take the mean $\\mu$ to be 0 and the standard deviation to be $\\sigma = \\frac{1}{2}$.\n",
    "\n",
    "**Question:** Why take $\\sigma = \\frac{1}{2}$?\n",
    "\n",
    "Recall that $\\sigma^2$ is the variance of the Gaussian distribution, so $\\sigma^2 = \\frac{1}{4}$ in this example. On the other hand, the variance of our random variable $X$ is \n",
    "$$\n",
    "\\mathbb{V}[X] = \\mathbb{E}[X^2] - \\mathbb{E}[X]^2 = \\mathbb{E}[X] - \\mathbb{E}[X]^2 = \\frac{1}{2} - \\frac{1}{4} = \\frac{1}{4}.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "So we are matching the variance of the Gaussian to the variance of the random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "st_dev = 1/2\n",
    "\n",
    "samples = np.random.normal(loc=mean, scale=st_dev, size=num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a plot of the histogram of samples we took:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "plt.hist(samples,bins = int(np.ceil(num_runs/50)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the shape of this histogram to the shape of our values in the experiment. Running the experiment for relatively low `n` (number of coin flips per run), but keeping the number of runs fixed, we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_n = 10\n",
    "\n",
    "means = []\n",
    "      \n",
    "for run in range(num_runs):\n",
    "    outcomes = []\n",
    "    for n in range(total_n):\n",
    "        outcome = toss_coin()\n",
    "        outcomes.append(outcome)\n",
    "    means.append(np.mean(outcomes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the correct comparison, we need to 'normalize' the means. We shift by the expected value, and rescale by $\\sqrt{n}$, where $n$ is the number of experiments in each run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_means = [np.sqrt(total_n)*(means[j]-0.5) for j in range(len(means))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the Gaussian and experimental distributions on the same axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "plt.hist(rescaled_means,bins = int(np.ceil(num_runs/50)),alpha = 0.4)\n",
    "plt.hist(samples,bins = int(np.ceil(num_runs/50)),alpha = 0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too similar... but let's see what happens as we make `n` larger (i.e., more coin flips per run):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [10,100,200,500,1000]\n",
    "\n",
    "for n in ns:\n",
    "    total_n = n\n",
    "    \n",
    "    means = []\n",
    "      \n",
    "    for run in range(num_runs):\n",
    "        outcomes = []\n",
    "        for n in range(total_n):\n",
    "            outcome = toss_coin()\n",
    "            outcomes.append(outcome)\n",
    "        means.append(np.mean(outcomes))\n",
    "    \n",
    "    rescaled_means = [np.sqrt(total_n)*(means[j]-0.5) for j in range(len(means))]\n",
    "    \n",
    "    plt.figure(figsize = (10,7))\n",
    "    plt.hist(rescaled_means,bins = int(np.ceil(num_runs/50)),alpha = 0.4)\n",
    "    plt.hist(samples,bins = int(np.ceil(num_runs/50)),alpha = 0.4)\n",
    "    plt.title(n+1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Conclusion\n",
    "\n",
    "Apparently, the deviation of the average number of tails over `n` coin tosses from the expected value of $\\frac{1}{2}$ is distributed like a Gaussian distribution, when `n` is large!\n",
    "\n",
    "This illustrates the **Central Limit Theorem**, which *roughly* says: The distribution of an appropriate normalization of the average of $n$ trials of a random variable $X$ is a Gaussian with $\\mu = 0$ and $\\sigma^2 = \\mathbb{V}[X]$. \n",
    "\n",
    "We will give a precise statement of this theorem in class."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
